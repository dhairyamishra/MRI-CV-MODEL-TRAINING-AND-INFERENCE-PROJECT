# SliceWise Scripts Directory - Comprehensive Guide

**Version:** 2.1.0 (Multi-Task + PM2 Integration)  
**Date:** December 8, 2025  
**Status:** ‚úÖ Production Ready  

---

## üéØ Executive Summary

The SliceWise scripts directory contains **25+ organized scripts** that implement a complete end-to-end pipeline for MRI brain tumor detection. Scripts are meticulously organized by functionality into 8 categories, providing a clear workflow from data acquisition to production deployment.

**Key Achievements:**
- ‚úÖ **25+ scripts** organized in hierarchical structure
- ‚úÖ **Complete pipeline automation** (6 stages, single command)
- ‚úÖ **Multi-task integration** (classification + segmentation)
- ‚úÖ **Production deployment** (PM2 process management)
- ‚úÖ **Comprehensive testing** (E2E validation suite)
- ‚úÖ **Error handling** and robust path management

---

## üèóÔ∏è Scripts Architecture Overview

### Why Organized Scripts Matter

**Problem Solved**: Traditional ML projects have scattered scripts causing:
- Maintenance difficulties
- Discovery challenges
- Workflow confusion
- Error-prone execution

**Solution**: Hierarchical organization by function and workflow stage:

```
scripts/
‚îú‚îÄ‚îÄ run_full_pipeline.py          # üéÆ SINGLE COMMAND PIPELINE
‚îú‚îÄ‚îÄ data/                         # üì¶ Data management
‚îú‚îÄ‚îÄ training/                     # üèãÔ∏è Model training
‚îú‚îÄ‚îÄ evaluation/                   # üìä Performance analysis
‚îú‚îÄ‚îÄ demo/                         # üé¨ Application deployment
‚îú‚îÄ‚îÄ utils/                        # üîß Configuration tools
‚îî‚îÄ‚îÄ debug/                        # üîç Development aids
```

### Organization Philosophy

1. **Functional Grouping**: Scripts grouped by primary function (data, training, etc.)
2. **Workflow Stages**: Clear progression from data ‚Üí training ‚Üí evaluation ‚Üí deployment
3. **Single Responsibility**: Each script has one clear purpose
4. **Path Consistency**: All scripts handle paths correctly from any execution location
5. **Error Resilience**: Robust error handling and validation

---

## üöÄ Master Controller: `run_full_pipeline.py`

### Why This Script Exists

The **full pipeline controller** is the single entry point for the complete SliceWise workflow. It eliminates the need to manually run 15+ individual scripts, providing:

- **One-command execution** for complete pipeline
- **Automated stage orchestration** with proper sequencing
- **Error recovery** and checkpoint management
- **Progress tracking** with colored terminal output
- **Flexible modes** for different use cases

### Pipeline Stages (6 Automated Steps)

```
1. üì• Data Download      ‚Üí 2. üîÑ Preprocessing      ‚Üí 3. ‚úÇÔ∏è Data Splitting
   BraTS + Kaggle          3D‚Üí2D conversion         Patient-level splits

4. üèãÔ∏è Multi-Task Training ‚Üí 5. üìä Evaluation         ‚Üí 6. üé¨ Demo Deployment
   3-stage pipeline        Metrics + Grad-CAM       FastAPI + Streamlit
```

### Usage Modes

#### Full Pipeline Mode (Recommended)
```bash
# Complete end-to-end execution
python scripts/run_full_pipeline.py --mode full --training-mode production

# Quick validation run
python scripts/run_full_pipeline.py --mode full --training-mode quick

# Baseline research run
python scripts/run_full_pipeline.py --mode full --training-mode baseline
```

#### Partial Pipeline Modes
```bash
# Data preparation only
python scripts/run_full_pipeline.py --mode data-only

# Training and evaluation only
python scripts/run_full_pipeline.py --mode train-eval

# Demo deployment only (requires trained models)
python scripts/run_full_pipeline.py --mode demo
```

### Key Features

#### Automated Workflow Orchestration
```python
# Example: Training stage execution
def run_training_stage():
    """Execute 3-stage multi-task training pipeline."""
    stages = [
        ("seg_warmup", train_multitask_seg_warmup),
        ("cls_head", train_multitask_cls_head),
        ("joint", train_multitask_joint)
    ]
    
    for stage_name, trainer in stages:
        print_colored(f"üöÄ Stage {stage_name}: Starting...", "blue")
        success = trainer(config_path, **kwargs)
        if not success:
            raise PipelineError(f"Stage {stage_name} failed")
```

#### Progress Tracking & Logging
- **Colored terminal output** with progress indicators
- **JSON results logging** to `pipeline_results.json`
- **Timeout management** for long-running stages
- **Error recovery** with informative messages

#### Expected Performance by Mode

| Mode | Training Time | Accuracy | Dice Score | Use Case |
|------|---------------|----------|------------|----------|
| **Quick** | 30 min | 75-85% | 0.60-0.70 | Development/testing |
| **Baseline** | 2-4 hours | 85-90% | 0.70-0.75 | Research experiments |
| **Production** | 8-12 hours | 91-93% | 0.75-0.80 | Final models |

### Configuration Integration

The controller uses the **hierarchical config system**:

```python
# Config paths (auto-generated from base/stages/modes)
CONFIG_DIR = "configs/final"
config_files = {
    'seg_warmup': f"{CONFIG_DIR}/stage1_{mode}.yaml",
    'cls_head': f"{CONFIG_DIR}/stage2_{mode}.yaml", 
    'joint': f"{CONFIG_DIR}/stage3_{mode}.yaml"
}
```

---

## üì¶ Data Pipeline Scripts (`scripts/data/`)

### Why Data Scripts Matter

Medical imaging requires meticulous data handling:
- **Large datasets** (BraTS: 15GB, 988 patients)
- **Complex preprocessing** (3D‚Üí2D conversion)
- **Patient-level splitting** (prevent data leakage)
- **Multi-modal integration** (FLAIR, T1, T1ce, T2)

### Data Collection (`data/collection/`)

#### `download_brats_data.py` - BraTS Dataset Acquisition
**Purpose**: Download and verify the BraTS 2020/2021 dataset from Kaggle.

**Key Features:**
- **Multi-version support**: BraTS 2020 (988 patients) and 2021 (1,470 patients)
- **Automatic verification**: File integrity checks and folder validation
- **Resume capability**: Continue interrupted downloads
- **Progress tracking**: Download progress with size estimates

**Usage:**
```bash
# Download BraTS 2020 (recommended)
python scripts/data/collection/download_brats_data.py --version 2020

# Download BraTS 2021 (larger dataset)
python scripts/data/collection/download_brats_data.py --version 2021

# Force re-download
python scripts/data/collection/download_brats_data.py --force
```

**Output Structure:**
```
data/raw/brats2020/
‚îú‚îÄ‚îÄ BraTS2020_TrainingData/     # 369 patients
‚îÇ   ‚îî‚îÄ‚îÄ MICCAI_BraTS2020_TrainingData/
‚îÇ       ‚îú‚îÄ‚îÄ BraTS20_Training_001/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ BraTS20_Training_001_flair.nii.gz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ BraTS20_Training_001_t1.nii.gz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ BraTS20_Training_001_t1ce.nii.gz
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ BraTS20_Training_001_t2.nii.gz
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ BraTS20_Training_001_seg.nii.gz
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ BraTS2020_ValidationData/   # 125 patients
```

#### `download_kaggle_data.py` - Classification Dataset
**Purpose**: Download Kaggle brain tumor classification dataset.

**Key Features:**
- **245 images** with binary tumor labels
- **Stratified classes**: 154 tumor (+), 91 no tumor (-)
- **Pre-cleaned data**: No preprocessing needed
- **Fast download**: ~500MB, 2-5 minutes

**Usage:**
```bash
python scripts/data/collection/download_kaggle_data.py
```

### Data Preprocessing (`data/preprocessing/`)

#### `preprocess_all_brats.py` - 3D‚Üí2D Conversion
**Purpose**: Convert BraTS 3D NIfTI volumes to 2D slices for CNN training.

**Complex Processing Pipeline:**
1. **Volume Loading**: Read NIfTI files (FLAIR, T1, T1ce, T2, segmentation)
2. **Brain Extraction**: Remove skull and background
3. **Registration**: Align all modalities to FLAIR space
4. **Slice Extraction**: Extract 2D slices from 3D volumes
5. **Normalization**: Z-score normalization per modality
6. **Quality Filtering**: Remove empty/background slices
7. **Metadata Generation**: Patient info, slice coordinates, quality metrics

**Usage:**
```bash
# Process all patients (988 total)
python scripts/data/preprocessing/preprocess_all_brats.py

# Process specific patients
python scripts/data/preprocessing/preprocess_all_brats.py --patient-ids 001 002 003

# Custom output directory
python scripts/data/preprocessing/preprocess_all_brats.py --output-dir data/processed/brats2d_custom
```

**Output Statistics:**
- **Input**: 988 patients √ó ~155 slices/patient √ó 4 modalities = ~614K images
- **Output**: ~45K high-quality 2D slices (256√ó256)
- **Processing time**: 5-15 minutes on modern hardware

#### `export_dataset_examples.py` - Visualization Samples
**Purpose**: Generate PNG examples for documentation and debugging.

**Features:**
- **Random sampling**: Representative slices from different patients
- **Multi-modal visualization**: FLAIR, T1, T1ce, T2, segmentation overlay
- **Quality assessment**: Display preprocessing results
- **JSON metadata**: Slice coordinates, patient IDs, quality scores

### Data Splitting (`data/splitting/`)

#### `split_brats_data.py` - Patient-Level Segmentation Splits
**Purpose**: Create train/validation/test splits preventing data leakage.

**Patient-Level Strategy:**
- **Unit of splitting**: Entire patient (not individual slices)
- **Ratio**: 70% train, 15% validation, 15% test
- **Leakage prevention**: All slices from one patient in same split
- **Stratification**: Balanced tumor presence across splits

**Usage:**
```bash
python scripts/data/splitting/split_brats_data.py

# Custom ratios
python scripts/data/splitting/split_brats_data.py --train-ratio 0.8 --val-ratio 0.1 --test-ratio 0.1
```

#### `split_kaggle_data.py` - Classification Splits
**Purpose**: Stratified splitting for classification dataset.

**Stratification Strategy:**
- **Class balance**: Maintain tumor/no-tumor ratios across splits
- **Patient level**: Group by patient when possible
- **Reproducibility**: Fixed random seed for consistent splits

---

## üèãÔ∏è Training Scripts (`scripts/training/`)

### Multi-Task Training Pipeline (`training/multitask/`)

#### Why 3-Stage Training

The multi-task model uses a **progressive training strategy**:

1. **Stage 1**: Learn spatial features (segmentation-only)
2. **Stage 2**: Learn classification (frozen encoder)
3. **Stage 3**: Joint optimization (all parameters)

This approach ensures optimal feature learning for both tasks.

#### `train_multitask_seg_warmup.py` - Stage 1
**Purpose**: Initialize shared encoder with segmentation task.

**Key Features:**
- **Segmentation-only training** (classification head disabled)
- **U-Net decoder training** (15.7M parameters)
- **Encoder feature learning** for spatial understanding
- **Foundation model** for subsequent stages

**Training Focus:**
- Loss: Dice + BCE (segmentation-focused)
- Data: BraTS with ground truth masks
- Duration: 10-20 minutes

#### `train_multitask_cls_head.py` - Stage 2
**Purpose**: Train classification head on frozen encoder.

**Key Features:**
- **Frozen encoder** (preserves segmentation features)
- **Classification head training** (263K parameters)
- **Differential learning rates** (encoder: 1e-5, head: 1e-4)
- **Mixed dataset** (BraTS + Kaggle)

**Training Focus:**
- Loss: Cross-entropy with label smoothing
- Data: Tumor presence labels
- Duration: 5-15 minutes

#### `train_multitask_joint.py` - Stage 3
**Purpose**: Joint fine-tuning of all parameters.

**Key Features:**
- **Unfrozen training** (31.7M parameters total)
- **Combined loss** (segmentation + classification)
- **Differential LR** (encoder: 1e-4, decoder/cls: 3e-4)
- **Task balancing** (weighted loss combination)

**Training Focus:**
- Loss: Combined Dice + BCE + Cross-entropy
- Data: Both BraTS (with masks) and Kaggle (classification only)
- Duration: 15-30 minutes

### Training Utilities (`training/utils/`)

#### `generate_model_configs.py` - Legacy Config Generation
**Purpose**: Generate YAML configs for training (superseded by hierarchical system).

**Note**: This script is maintained for backward compatibility but the **hierarchical config system** (`scripts/utils/merge_configs.py`) is now preferred.

---

## üìä Evaluation Scripts (`scripts/evaluation/`)

### Multi-Task Evaluation (`evaluation/multitask/`)

#### `evaluate_multitask.py` - Comprehensive Assessment
**Purpose**: Evaluate trained multi-task model on test set.

**Metrics Computed:**
- **Classification**: Accuracy, Precision, Recall, F1, ROC-AUC, PR-AUC
- **Segmentation**: Dice, IoU, Pixel Accuracy, Specificity
- **Combined**: Harmonic mean of classification and segmentation
- **Patient-level**: Tumor detection rate, volume estimation

**Output Files:**
```
results/multitask_evaluation/
‚îú‚îÄ‚îÄ metrics.json              # All performance metrics
‚îú‚îÄ‚îÄ classification_report.csv # Per-class classification results
‚îú‚îÄ‚îÄ segmentation_metrics.json # Dice, IoU by threshold
‚îú‚îÄ‚îÄ patient_analysis.csv      # Patient-level results
‚îî‚îÄ‚îÄ confusion_matrix.png      # Classification visualization
```

#### `generate_multitask_gradcam.py` - Explainability
**Purpose**: Generate Grad-CAM visualizations for model interpretability.

**Features:**
- **Attention mapping**: Shows which image regions influenced predictions
- **Multi-sample generation**: Up to 100 visualization examples
- **Quality filtering**: Only generate for confident predictions
- **Overlay creation**: Original image + heatmap + mask

**Usage:**
```bash
python scripts/evaluation/multitask/generate_multitask_gradcam.py --num-samples 50
```

#### `compare_all_phases.py` - Phase Comparison
**Purpose**: Statistical comparison of training phases.

**Analysis:**
- **Phase progression**: Seg warmup ‚Üí Cls head ‚Üí Joint
- **Performance gains**: Quantify improvements at each stage
- **Statistical significance**: p-values for performance differences
- **Trade-off analysis**: Accuracy vs segmentation quality

### Testing Suite (`evaluation/testing/`)

#### `test_multitask_e2e.py` - End-to-End Validation
**Purpose**: Comprehensive pipeline testing from data to inference.

**Test Coverage:**
- **Data pipeline**: Loading, preprocessing, batching
- **Model initialization**: Checkpoint loading, parameter counts
- **Inference pipeline**: Single/batch prediction, postprocessing
- **Integration**: API endpoints, frontend communication
- **Performance**: Latency, throughput, memory usage

**Execution:**
```bash
# Full test suite (30-60 seconds)
python scripts/evaluation/testing/test_multitask_e2e.py

# Verbose output
python scripts/evaluation/testing/test_multitask_e2e.py --verbose
```

#### `test_backend_startup.py` - API Validation
**Purpose**: Validate FastAPI backend startup and endpoints.

**Checks:**
- **Model loading**: All models load without errors
- **Health endpoint**: `/healthz` returns correct status
- **Model info**: `/model/info` provides metadata
- **CORS**: Cross-origin headers configured

#### `test_brain_crop.py` - Preprocessing Validation
**Purpose**: Test brain extraction and cropping algorithms.

---

## üé¨ Demo Scripts (`scripts/demo/`)

### PM2-Based Deployment (`run_demo_pm2.py`)

#### Why PM2 Matters

**Problem Solved**: Windows subprocess management issues
- Traditional `subprocess` calls unreliable on Windows
- No auto-restart on crashes
- Manual process monitoring required
- Difficult cleanup and log management

**PM2 Solution:**
- **Cross-platform**: Works on Windows, Linux, macOS
- **Auto-restart**: Automatic recovery from failures
- **Process monitoring**: Real-time status and resource tracking
- **Log management**: Centralized logging in `logs/` directory
- **Memory limits**: Prevent memory leaks

#### Key Features

**Health Monitoring:**
```python
def check_backend_health():
    """Verify backend is responding."""
    try:
        response = requests.get(f"{BACKEND_URL}/healthz", timeout=5)
        return response.status_code == 200
    except:
        return False
```

**Process Management:**
```bash
# Start demo
python scripts/demo/run_demo_pm2.py

# Monitor processes
pm2 status              # View running processes
pm2 logs               # View logs in real-time
pm2 monit              # Interactive monitoring dashboard

# Stop demo
pm2 stop all           # Graceful shutdown
pm2 delete all         # Remove processes
```

**Log Structure:**
```
logs/
‚îú‚îÄ‚îÄ backend-error.log      # Backend stderr
‚îú‚îÄ‚îÄ backend-out.log        # Backend stdout
‚îú‚îÄ‚îÄ backend-combined.log   # Combined backend logs
‚îú‚îÄ‚îÄ frontend-error.log     # Frontend stderr
‚îú‚îÄ‚îÄ frontend-out.log       # Frontend stdout
‚îî‚îÄ‚îÄ frontend-combined.log  # Combined frontend logs
```

### Legacy Demo Scripts

#### `run_demo.py` - Original Demo
**Purpose**: Launch demo with separate models (classification + segmentation).

**Note**: Superseded by `run_demo_pm2.py` but maintained for compatibility.

#### `manual_demo_backend.py` & `manual_demo_frontend.py`
**Purpose**: Individual component launchers for development.

**Use Cases:**
- Backend development (API testing)
- Frontend development (UI changes)
- Debugging specific components

---

## üîß Utility Scripts (`scripts/utils/`)

### Configuration Management (`merge_configs.py`)

#### Why This Script Exists

The **config merger** is the heart of the hierarchical configuration system. It transforms modular config components into complete training configurations.

**Core Functionality:**
- **Deep merging**: Combine base ‚Üí stage ‚Üí mode configs
- **Reference resolution**: Expand architecture/model presets
- **Validation**: Ensure config consistency
- **Metadata**: Track config provenance and generation time

#### Usage Examples

```bash
# Generate all 9 configs (stage1-3 √ó quick/baseline/production)
python scripts/utils/merge_configs.py --all

# Generate specific config
python scripts/utils/merge_configs.py --stage 1 --mode baseline

# Custom output directory
python scripts/utils/merge_configs.py --all --output-dir configs/custom
```

#### Technical Implementation

**Merge Algorithm:**
```python
def deep_merge(base: Dict, override: Dict) -> Dict:
    """Recursively merge dictionaries."""
    result = base.copy()
    for key, value in override.items():
        if key in result and isinstance(result[key], dict):
            result[key] = deep_merge(result[key], value)
        else:
            result[key] = value
    return result
```

**Reference Resolution:**
```yaml
# Input (stage config)
model:
  architecture: "multitask_medium"

# Output (resolved)
model:
  base_filters: 32
  depth: 4
  cls_hidden_dim: 64
  # ... full architecture config
```

---

## üîç Debug Scripts (`scripts/debug/`)

### `debug_multitask_data.py` - Data Pipeline Debugging

**Purpose**: Inspect and validate data loading pipeline.

**Validation Checks:**
- **Dataset initialization**: Correct class instantiation
- **Batch collation**: Proper tensor shapes and types
- **Mixed source handling**: BraTS + Kaggle integration
- **Mask availability**: Segmentation masks present when expected
- **Data statistics**: Distribution analysis and quality metrics

**Usage:**
```bash
python scripts/debug/debug_multitask_data.py --batch-size 4 --num-batches 10
```

---

## üìã Complete Workflow Examples

### First-Time Setup (New User)

```bash
# 1. Generate training configs
python scripts/utils/merge_configs.py --all

# 2. Download datasets
python scripts/data/collection/download_brats_data.py
python scripts/data/collection/download_kaggle_data.py

# 3. Preprocess data
python scripts/data/preprocessing/preprocess_all_brats.py

# 4. Split datasets
python scripts/data/splitting/split_brats_data.py
python scripts/data/splitting/split_kaggle_data.py

# 5. Train multi-task model (3 stages)
python scripts/training/multitask/train_multitask_seg_warmup.py
python scripts/training/multitask/train_multitask_cls_head.py
python scripts/training/multitask/train_multitask_joint.py

# 6. Evaluate performance
python scripts/evaluation/multitask/evaluate_multitask.py

# 7. Launch demo
python scripts/demo/run_demo_pm2.py
```

### Using Full Pipeline Controller (Recommended)

```bash
# Single command for complete pipeline
python scripts/run_full_pipeline.py --mode full --training-mode baseline
```

### Research & Development

```bash
# Quick iteration cycle
python scripts/run_full_pipeline.py --mode full --training-mode quick

# Detailed evaluation
python scripts/evaluation/multitask/generate_multitask_gradcam.py --num-samples 100
python scripts/evaluation/multitask/compare_all_phases.py

# Debug data issues
python scripts/debug/debug_multitask_data.py
```

### Production Deployment

```bash
# Generate production configs
python scripts/utils/merge_configs.py --stage 3 --mode production

# Train production model
python scripts/training/multitask/train_multitask_joint.py --config configs/final/stage3_production.yaml

# Launch production demo
python scripts/demo/run_demo_pm2.py
```

---

## üîß Technical Implementation Details

### Path Management Strategy

**Challenge**: Scripts run from different locations, paths must be resolved correctly.

**Solution**: Dynamic path calculation based on script location:

```python
# Scripts in scripts/subdir/ (3 levels deep)
project_root = Path(__file__).parent.parent.parent

# Scripts in scripts/ (2 levels deep)  
project_root = Path(__file__).parent.parent
```

### Error Handling Patterns

**Robust Error Recovery:**
```python
try:
    # Operation that might fail
    result = risky_operation()
except Exception as e:
    logger.error(f"Operation failed: {e}")
    # Graceful degradation or user notification
    return fallback_result()
```

### Logging Strategy

**Comprehensive Logging:**
- **File logging**: All operations logged to files
- **Console output**: User-friendly progress indicators
- **Structured logging**: JSON format for analysis
- **Log levels**: DEBUG, INFO, WARNING, ERROR

### Performance Optimizations

**GPU Utilization:**
- **Mixed precision**: Automatic mixed precision (AMP)
- **Memory pinning**: `pin_memory=True` for faster GPU transfer
- **Batch optimization**: Optimal batch sizes per GPU memory

**Parallel Processing:**
- **Data loading**: Multiple workers for CPU preprocessing
- **Batch processing**: Vectorized operations where possible
- **Async I/O**: Non-blocking file operations

---

## üìä Scripts Statistics

### By Category

| Category | Scripts | Lines of Code | Primary Function |
|----------|---------|---------------|------------------|
| **Pipeline Control** | 1 | 727 | Orchestration |
| **Data Management** | 6 | ~15K | Data pipeline |
| **Training** | 4 | ~12K | Model training |
| **Evaluation** | 6 | ~20K | Performance analysis |
| **Demo Deployment** | 5 | ~15K | Application serving |
| **Utilities** | 1 | 8K | Configuration |
| **Debug** | 1 | 5K | Development |

### Execution Times (Approximate)

| Operation | Quick Mode | Baseline Mode | Production Mode |
|-----------|------------|----------------|-----------------|
| **Data Download** | 10 min | 10 min | 10 min |
| **Preprocessing** | 5 min | 5 min | 5 min |
| **Stage 1 Training** | 10 min | 20 min | 40 min |
| **Stage 2 Training** | 5 min | 10 min | 20 min |
| **Stage 3 Training** | 15 min | 30 min | 60 min |
| **Evaluation** | 2 min | 2 min | 2 min |
| **Total Pipeline** | **47 min** | **1.5 hours** | **2.5 hours** |

### Quality Metrics

- **Test Coverage**: 25/25 E2E tests passing
- **Error Handling**: Comprehensive exception handling
- **Documentation**: Detailed docstrings in all scripts
- **Path Safety**: All scripts work from any directory
- **Cross-Platform**: Windows, Linux, macOS compatibility

---

## üö® Troubleshooting Guide

### Common Issues & Solutions

#### "Script not found" or "Module not found"
```bash
# Ensure running from project root
cd /path/to/MRI-CV-MODEL-TRAINING-AND-INFERENCE-PROJECT

# Verify script exists
ls -la scripts/run_full_pipeline.py

# Check Python path
python -c "import sys; print(sys.path)"
```

#### "CUDA out of memory"
```bash
# Reduce batch size in config
vim configs/final/stage3_quick.yaml
# Change: batch_size: 32 ‚Üí batch_size: 16

# Use gradient accumulation
# Add to config: gradient_accumulation_steps: 2
```

#### "Checkpoint not found"
```bash
# Check training completed
ls -la checkpoints/multitask_joint/

# Resume training if interrupted
python scripts/training/multitask/train_multitask_joint.py --resume
```

#### PM2 Issues
```bash
# Check PM2 installation
pm2 --version

# Restart services
pm2 restart slicewise-backend slicewise-frontend

# Clear logs if too large
pm2 flush
```

#### Data Download Failures
```bash
# Check Kaggle API key
ls -la ~/.kaggle/kaggle.json

# Verify internet connection
ping www.kaggle.com

# Resume partial downloads
python scripts/data/collection/download_brats_data.py --force
```

### Debug Mode Execution

```bash
# Enable verbose logging
export PYTHONPATH=/path/to/project:$PYTHONPATH
python scripts/evaluation/testing/test_multitask_e2e.py --verbose --debug

# Single-step pipeline execution
python scripts/run_full_pipeline.py --mode data-only --verbose
```

---

## üîÆ Future Enhancements

### Planned Features

- **Distributed Training**: Multi-GPU support with DDP
- **Model Registry**: Versioned model storage and retrieval
- **Hyperparameter Optimization**: Automated parameter search
- **CI/CD Integration**: Automated testing and deployment
- **Monitoring Dashboard**: Real-time performance monitoring

### Research Applications

- **Automated Architecture Search**: Dynamic model size selection
- **Federated Learning**: Multi-institution collaboration
- **Meta-Learning**: Cross-dataset generalization
- **Active Learning**: Intelligent data sampling

---

## üìö Related Documentation

- **[README.md](../README.md)** - Project overview and quick start
- **[PIPELINE_CONTROLLER_GUIDE.md](documentation/PIPELINE_CONTROLLER_GUIDE.md)** - Full pipeline usage
- **[CONFIG_SYSTEM_ARCHITECTURE.md](documentation/CONFIG_SYSTEM_ARCHITECTURE.md)** - Configuration system
- **[APP_ARCHITECTURE_AND_FUNCTIONALITY.md](documentation/APP_ARCHITECTURE_AND_FUNCTIONALITY.md)** - Application architecture

---

*Built with ‚ù§Ô∏è for reproducible, scalable medical AI research.*
