# ============================================================================
# SliceWise - 2D Segmentation Training Configuration
# ============================================================================
# Configuration for training U-Net on BraTS 2D slices

# Experiment metadata
experiment:
  name: "unet_brats_baseline"
  description: "Baseline U-Net for brain tumor segmentation on BraTS 2D slices"
  tags: ["unet", "segmentation", "brats", "flair"]

# Paths
paths:
  train_dir: "data/processed/brats2d/train"
  val_dir: "data/processed/brats2d/val"
  test_dir: "data/processed/brats2d/test"
  checkpoint_dir: "checkpoints/seg"
  log_dir: "logs/seg"
  output_dir: "outputs/seg"

# Model architecture
model:
  name: "unet2d"
  in_channels: 1          # Single-channel MRI (FLAIR)
  out_channels: 1         # Binary segmentation
  base_filters: 64        # Base number of filters
  depth: 4                # Number of encoder/decoder blocks
  use_bilinear: true      # Use bilinear upsampling (vs transposed conv)

# Loss function
loss:
  name: "dice_bce"        # Options: dice, bce, dice_bce, tversky, focal
  dice_weight: 0.5        # Weight for Dice loss (if using dice_bce)
  bce_weight: 0.5         # Weight for BCE loss (if using dice_bce)
  smooth: 1.0             # Smoothing factor for Dice loss
  # Tversky loss parameters (if using tversky)
  alpha: 0.5              # False positive weight
  beta: 0.5               # False negative weight
  # Focal loss parameters (if using focal)
  focal_alpha: 0.25
  focal_gamma: 2.0

# Optimizer
optimizer:
  name: "adam"            # Options: adam, adamw, sgd
  lr: 0.001               # Learning rate
  weight_decay: 0.0001    # L2 regularization
  # Adam/AdamW specific
  betas: [0.9, 0.999]
  eps: 1.0e-8
  # SGD specific
  momentum: 0.9
  nesterov: true

# Learning rate scheduler
scheduler:
  name: "cosine"          # Options: cosine, step, plateau, none
  # Cosine annealing
  T_max: 10              # Maximum number of iterations
  eta_min: 1.0e-6         # Minimum learning rate
  # Step scheduler
  step_size: 30           # Period of learning rate decay
  gamma: 0.1              # Multiplicative factor
  # ReduceLROnPlateau
  mode: "min"             # min or max
  factor: 0.5             # Factor by which LR is reduced
  patience: 10            # Number of epochs with no improvement
  threshold: 0.0001       # Threshold for measuring improvement

# Training hyperparameters
training:
  epochs: 10
  batch_size: 16
  num_workers: 4
  pin_memory: true
  
  # Mixed precision training
  use_amp: true           # Automatic Mixed Precision
  
  # Gradient clipping
  grad_clip: 1.0          # Max gradient norm (0 to disable)
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 15          # Epochs to wait for improvement
    min_delta: 0.001      # Minimum change to qualify as improvement
    monitor: "val_dice"   # Metric to monitor
    mode: "max"           # max or min
  
  # Checkpoint saving
  save_best: true         # Save best model based on val metric
  save_last: true         # Save last checkpoint
  save_frequency: 5       # Save every N epochs (0 to disable)
  keep_last_n: 3          # Keep only last N checkpoints

# Validation
validation:
  frequency: 1            # Validate every N epochs
  metric: "dice"          # Primary metric (dice, iou)

# Data augmentation
augmentation:
  train:
    enabled: true
    random_flip_h: 0.5    # Horizontal flip probability
    random_flip_v: 0.5    # Vertical flip probability
    random_rotate: 15     # Random rotation degrees
    random_scale: 0.1     # Random scale factor
    elastic_deform: false # Elastic deformation (expensive)
    gaussian_noise: 0.01  # Gaussian noise std (0 to disable)
  val:
    enabled: false        # No augmentation for validation

# Logging
logging:
  use_wandb: true
  wandb_project: "slicewise-segmentation"
  wandb_entity: null      # Your W&B username (null for default)
  log_frequency: 10       # Log every N batches
  log_images: true        # Log example predictions
  log_images_frequency: 5 # Log images every N epochs
  num_images_to_log: 4    # Number of images to log

# Evaluation metrics
metrics:
  - "dice"                # Dice coefficient
  - "iou"                 # Intersection over Union
  - "precision"           # Precision
  - "recall"              # Recall
  - "f1"                  # F1 score

# Reproducibility
seed: 42

# Device
device: "cuda"            # cuda or cpu (auto-detected if cuda available)

# Resume training
resume:
  enabled: false
  checkpoint_path: null   # Path to checkpoint to resume from
