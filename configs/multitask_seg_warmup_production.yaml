# ============================================================================
# Phase 2.1: Segmentation Warm-Up Configuration - QUICK TEST
# ============================================================================
# Train encoder + decoder on BraTS segmentation to initialize shared encoder
# This is Stage 1 of 3-stage multi-task training strategy
# QUICK TEST MODE: Full dataset, 3 epochs, ~5-10 minutes
# 
# IMPORTANT: PyTorch 2.6+ requires weights_only=False when loading checkpoints
# IMPORTANT: Windows requires num_workers=0 for DataLoader

# Experiment metadata
experiment:
  name: "multitask_seg_warmup_quick_test"
  description: "Phase 2.1 QUICK TEST - Segmentation warm-up for fast testing"
  tags: ["multitask", "segmentation", "warmup", "brats", "encoder_init", "quick_test"]
  notes: "Quick test with 3 epochs for rapid validation"

# Paths
paths:
  train_dir: "data/processed/brats2d_full/train"
  val_dir: "data/processed/brats2d_full/val"
  test_dir: "data/processed/brats2d_full/test"
  checkpoint_dir: "checkpoints/multitask_seg_warmup_quick_test"
  log_dir: "logs/multitask_seg_warmup_quick_test"
  output_dir: "outputs/multitask_seg_warmup_quick_test"

# Model architecture (MultiTaskModel in seg-only mode)
model:
  name: "multitask"
  in_channels: 1          # Single-channel MRI (FLAIR)
  out_channels: 1         # Binary segmentation
  base_filters: 32        # Base number of filters
  depth: 4                # Number of encoder/decoder blocks

# Loss function
loss:
  name: "dice_bce"        # Combined Dice + BCE loss
  dice_weight: 0.6        # Weight for Dice loss
  bce_weight: 0.4         # Weight for BCE loss
  smooth: 1.0             # Smoothing factor for Dice loss

# Optimizer
optimizer:
  name: "adamw"           # AdamW optimizer
  lr: 0.0003              # Slightly lower LR for production
  weight_decay: 0.0001    # L2 regularization
  betas: [0.9, 0.999]
  eps: 1.0e-8

# Learning rate scheduler
scheduler:
  name: "cosine"          # Cosine annealing
  T_max: 3                # Match number of epochs
  eta_min: 1.0e-7         # Minimum learning rate

# Training hyperparameters
training:
  epochs: 3               # REDUCED for quick test
  batch_size: 64          # INCREASED for faster iterations
  num_workers: 0          # Set to 0 for Windows compatibility (use 4+ on Linux/Mac)
  pin_memory: true
  
  # Mixed precision training
  use_amp: true           # Automatic Mixed Precision
  
  # Gradient clipping
  grad_clip: 1.0          # Max gradient norm
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 10          # REDUCED patience
    min_delta: 0.0005     # Smaller delta for fine improvements
    monitor: "val_dice"   # Metric to monitor
    mode: "max"           # max or min
  
  # Checkpoint saving
  save_best: true         # Save best model based on val metric
  save_last: true         # Save last checkpoint
  save_frequency: 10      # Save every 10 epochs
  keep_last_n: 5          # Keep last 5 checkpoints
  save_optimizer: true
  save_scheduler: true

# Data augmentation
augmentation:
  train:
    enabled: true
    random_flip_h: 0.5    # Horizontal flip probability
    random_flip_v: 0.5    # Vertical flip probability
    random_rotate: 15     # REDUCED rotation
    random_scale: 0.1     # REDUCED scale
    elastic_deform: false # DISABLED for speed
    elastic_alpha: 50     # Elastic deformation strength
    elastic_sigma: 5      # Elastic deformation smoothness
    gaussian_noise: 0.01  # REDUCED noise
    gaussian_blur: 0.2    # REDUCED blur
    brightness: 0.15      # REDUCED brightness
    contrast: 0.15        # REDUCED contrast
    gamma: 0.15           # REDUCED gamma
  val:
    enabled: false        # No augmentation for validation

# Weights & Biases logging
wandb:
  enabled: false          # DISABLED for quick test
  project: "slicewise-multitask-production"
  entity: null            # Set to your W&B username/team
  name: "seg_warmup_production"
  tags: ["production", "stage1", "segmentation", "warmup"]
  notes: "Production training with full dataset"

# Reproducibility
seed: 42

# Device
device: "cuda"            # cuda or cpu
